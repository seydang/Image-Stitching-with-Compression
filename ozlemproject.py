# -*- coding: utf-8 -*-
"""OzlemProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17IwAT8O48D4BtwQ7TfbBAGFnE41ryA0a

##setup
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install compressai
# !pip install -i https://test.pypi.org/simple/ imgstitch

import argparse
import random
import shutil
import sys

import torch
import torch.nn as nn
import torch.optim as optim

from torch.utils.data import DataLoader
from torchvision import transforms

# from compressai.datasets import ImageFolder
from compressai.losses import RateDistortionLoss
from compressai.optimizers import net_aux_optimizer
from compressai.zoo import image_models


class AverageMeter:
    """Compute running average."""

    def __init__(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


class CustomDataParallel(nn.DataParallel):
    """Custom DataParallel to access the module methods."""

    def __getattr__(self, key):
        try:
            return super().__getattr__(key)
        except AttributeError:
            return getattr(self.module, key)


def configure_optimizers(net, args):
    """Separate parameters for the main optimizer and the auxiliary optimizer.
    Return two optimizers"""
    conf = {
        "net": {"type": "Adam", "lr": args.learning_rate},
        "aux": {"type": "Adam", "lr": args.aux_learning_rate},
    }
    optimizer = net_aux_optimizer(net, conf)
    return optimizer["net"], optimizer["aux"]

from google.colab import drive
drive.mount('/content/MyDrive')

"""##data"""

from pathlib import Path, PosixPath
from PIL import Image
from torch.utils.data import Dataset
import numpy as np

class ImageFolder(Dataset):
    """Load an image folder database. Training and testing image samples
    are respectively stored in separate directories:
    .. code-block::
        - rootdir/
            - train/
                -cons
                    - 1
                        - scene1_1.jpg
                        - scene1_2.jpg
                        ...
                -stitch
                    - 1.jpg


    Args:
        root (string): root directory of the dataset
        transform (callable, optional): a function or transform that takes in a
            PIL image and returns a transformed version
        split (string): split mode ('train' or 'val')
    """

    def __init__(self, root, transform=None, split="train"):
        splitdir = Path(root) / split
        stitch_dir = Path(root) / split / 'stitch'
        cons_dir_ = Path(root) / split / 'cons'

        if not splitdir.is_dir():
            raise RuntimeError(f'Invalid directory "{root}"')

        self.cons_samples = []
        self.stitch_samples = []
        for fi in stitch_dir.iterdir():
          b = str.split(str(fi),str(stitch_dir) + '/')[1]
          a = str.split(b,'.jpg')[0]
          cons_dir = str(cons_dir_) + '/' + a

          # self.cons_samples = sorted(f for f in Path(cons_dir).iterdir() if f.is_file() for fi in Path(stitch_dir).iterdir() if fi.is_file() )
          self.stitch_samples.append(sorted(f for f in Path(stitch_dir).iterdir() if f.is_file()))
          
          self.cons_samples.append(sorted(f for f in Path(cons_dir).iterdir() if f.is_file()))



        self.transform = transform

    def __getitem__(self, index):
        """
        Args:
            index (int): Index
        Returns:
            img: `PIL.Image.Image` or transformed `PIL.Image.Image`.
        """
        # print(self.cons_samples)
        # print(self.stitch_samples)
        img1 = Image.open(self.cons_samples[index][0]).convert("RGB")
        img2 = Image.open(self.cons_samples[index][1]).convert("RGB")
        img3 = Image.open(self.cons_samples[index][2]).convert("RGB")
        img4 = Image.open(self.cons_samples[index][3]).convert("RGB")
        img5 = Image.open(self.cons_samples[index][4]).convert("RGB")
        
        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)
            img3 = self.transform(img3)
            img4 = self.transform(img4)
            img5 = self.transform(img5)

        img1_np = np.asarray(img1)
        img2_np = np.asarray(img2)
        img3_np = np.asarray(img3)
        img4_np = np.asarray(img4)
        img5_np = np.asarray(img5)

        img_stitch = np.asarray(Image.open(self.stitch_samples[index][0]).convert("RGB"))

        img_cons = np.concatenate((img1_np, img2_np, img3_np, img4_np, img5_np), axis=0)
        # img_cons = np.transpose(img_cons, (1,2,0))
        img_stitch = np.resize(img_stitch, img1_np.shape)
        # img_stitch = np.transpose(img_stitch, (1,2,0))


        # print(img_stitch.shape)
        # print(img_cons.shape)

        return img_cons, img_stitch

    def __len__(self):
        return len(self.cons_samples)

"""##code"""

def train_one_epoch(
    model, criterion, train_dataloader, optimizer, aux_optimizer, epoch, clip_max_norm
):
    model.train()
    device = next(model.parameters()).device

    for i, d in enumerate(train_dataloader):
        # d = np.asarray(d)
        # print(i)
        image = d[0].to(device)
        target = d[1].to(device).to(torch.float32)
        # print(image.size())
        # print(target.size())
        optimizer.zero_grad()
        aux_optimizer.zero_grad()

        out_net = model(image)

        out_criterion = criterion(out_net, target)

        out_criterion["loss"].backward()
        if clip_max_norm > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)
        optimizer.step()

        aux_loss = model.aux_loss()
        aux_loss.backward()
        aux_optimizer.step()

        if i % 10 == 0:
            print(
                f"Train epoch {epoch}: ["
                f"{i*len(d)}/{len(train_dataloader.dataset)}"
                f" ({100. * i / len(train_dataloader):.0f}%)]"
                f'\tLoss: {out_criterion["loss"].item():.3f} |'
                f'\tMSE loss: {out_criterion["mse_loss"].item():.3f} |'
                f'\tBpp loss: {out_criterion["bpp_loss"].item():.2f} |'
                f"\tAux loss: {aux_loss.item():.2f}"
            )


def test_epoch(epoch, test_dataloader, model, criterion):
    print('test')
    model.eval()
    device = next(model.parameters()).device

    loss = AverageMeter()
    bpp_loss = AverageMeter()
    mse_loss = AverageMeter()
    aux_loss = AverageMeter()

    with torch.no_grad():
        for d in test_dataloader:
            image = d[0].to(device)
            target = d[1].to(device)
            out_net = model(image)
            out_criterion = criterion(out_net, target)

            aux_loss.update(model.aux_loss())
            bpp_loss.update(out_criterion["bpp_loss"])
            loss.update(out_criterion["loss"])
            mse_loss.update(out_criterion["mse_loss"])

    print(
        f"Test epoch {epoch}: Average losses:"
        f"\tLoss: {loss.avg:.3f} |"
        f"\tMSE loss: {mse_loss.avg:.3f} |"
        f"\tBpp loss: {bpp_loss.avg:.2f} |"
        f"\tAux loss: {aux_loss.avg:.2f}\n"
    )

    return loss.avg


def save_checkpoint(state, is_best, filename="checkpoint.pth.tar"):
    torch.save(state, filename)
    if is_best:
        shutil.copyfile(filename, "checkpoint_best_loss.pth.tar")

"""##main"""

def main():

    class arguments:
      def __init__(self):
        self.model = 'bmshj2018-hyperprior'
        self.num_workers = 1
        self.dataset = '/content/MyDrive/MyDrive/ex_data'
        self.batch_size = 2
        self.test_batch_size = 2
        self.cuda = True
        self.epochs = 100
        self.patch_size = 64
        self.learning_rate = 0.001
        self.aux_learning_rate = 0.001
        self.lmbda = 0.001
        self.lmbda2 = 1
        self.save = True
        self.seed = False
        self.clip_max_norm = 1.0
        self.checkpoint = False

    args = arguments()

    if args.seed is not None:
        torch.manual_seed(args.seed)
        random.seed(args.seed)

    train_transforms = transforms.Compose(
        [transforms.RandomCrop(args.patch_size), transforms.ToTensor()]
    )

    test_transforms = transforms.Compose(
        [transforms.CenterCrop(args.patch_size), transforms.ToTensor()]
    )

    train_dataset = ImageFolder(args.dataset, split="train", transform=train_transforms)
    test_dataset = ImageFolder(args.dataset, split="train", transform=test_transforms)

    device = "cuda" if args.cuda and torch.cuda.is_available() else "cpu"

    train_dataloader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        shuffle=True,
        pin_memory=(device == "cuda"),
    )

    test_dataloader = DataLoader(
        test_dataset,
        batch_size=args.test_batch_size,
        num_workers=args.num_workers,
        shuffle=False,
        pin_memory=(device == "cuda"),
    )

    net = image_models[args.model](quality=3)
    ############## to give 5 different images:
    net.g_a[0] = torch.nn.Conv2d(15, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)) 
    ##########################################
    net = net.to(device)

    if args.cuda and torch.cuda.device_count() > 1:
        net = CustomDataParallel(net)

    optimizer, aux_optimizer = configure_optimizers(net, args)
    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, "min")
    criterion = RateDistortionLoss(lmbda=args.lmbda)

    last_epoch = 0
    if args.checkpoint:  # load from previous checkpoint
        print("Loading", args.checkpoint)
        checkpoint = torch.load(args.checkpoint, map_location=device)
        last_epoch = checkpoint["epoch"] + 1
        net.load_state_dict(checkpoint["state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer"])
        aux_optimizer.load_state_dict(checkpoint["aux_optimizer"])
        lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])

    best_loss = float("inf")
    for epoch in range(last_epoch, args.epochs):
        print(f"Learning rate: {optimizer.param_groups[0]['lr']}")
        train_one_epoch(
            net,
            criterion,
            train_dataloader,
            optimizer,
            aux_optimizer,
            epoch,
            args.clip_max_norm,
        )
        loss = test_epoch(epoch, test_dataloader, net, criterion)
        lr_scheduler.step(loss)

        is_best = loss < best_loss
        best_loss = min(loss, best_loss)

        if args.save:
            save_checkpoint(
                {
                    "epoch": epoch,
                    "state_dict": net.state_dict(),
                    "loss": loss,
                    "optimizer": optimizer.state_dict(),
                    "aux_optimizer": aux_optimizer.state_dict(),
                    "lr_scheduler": lr_scheduler.state_dict(),
                },
                is_best,
            )

"""##train"""

main()